{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation with GPT-2 using Hugging Face Transformers\n",
    "\n",
    "This notebook demonstrates how to use a pre-trained Transformer model (GPT-2) from Hugging Face's Transformers library to generate text based on a user-provided prompt.\n",
    "\n",
    "**Transformers** are a type of deep learning model architecture that has significantly advanced fields like natural language processing (NLP) and computer vision. In this notebook, we'll use a pre-trained Transformer model (GPT-2) to generate text based on an input prompt.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First, ensure that you have the necessary libraries installed. We'll use `transformers` from Hugging Face and `torch` (PyTorch) for tensor computations.\n",
    "\n",
    "```python\n",
    "# Install the required libraries\n",
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with GPT-2\n",
    "We'll define a function generate_text that takes a prompt and generates continuation text using the GPT-2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "def generate_text(prompt, max_length=150, temperature=0.8, top_k=50, top_p=0.95, repetition_penalty=1.2):\n",
    "    \"\"\"\n",
    "    Generate text using GPT-2 based on the given prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input text to base the generation on.\n",
    "        max_length (int): Maximum number of tokens to generate.\n",
    "        temperature (float): Sampling temperature. Higher values mean more random.\n",
    "        top_k (int): Top-k filtering.\n",
    "        top_p (float): Top-p (nucleus) filtering.\n",
    "        repetition_penalty (float): Penalty for repeating tokens.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text.\n",
    "    \"\"\"\n",
    "    # Load pre-trained model and tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    \n",
    "    # Set pad token to eos token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Encode the input prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    # Create attention mask (all ones since there's no padding)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "    \n",
    "    # Generate text\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=repetition_penalty\n",
    "        )\n",
    "    \n",
    "    # Decode the generated tokens\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b4ab9e3c5246249974eef6498eb216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='Once upon a time', description='Prompt:', layout=Layout(width='80%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0d11f4375f46bfa4b65d6f68e13659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='100', description='Max Length:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d721851df6046d0864d973ccfd21afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='0.7', description='Temperature:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944272a8ae524ca2b6f48304ad283872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='50', description='Top K:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1508dd93014b079d9980b36da0a832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='0.95', description='Top P:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd0ab3a9a564015b3093dac803b3c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283c042b8a0747d9a4fe2cf3895bd32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Output:', layout=Layout(height='200px', width='80%'), placeholder='Generated tâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_button_click(b):\n",
    "    prompt = text_input.value\n",
    "    max_length = int(max_length_input.value)\n",
    "    temperature = float(temperature_input.value)\n",
    "    top_k = int(top_k_input.value)\n",
    "    top_p = float(top_p_input.value)\n",
    "    \n",
    "    generated = generate_text(prompt, max_length=max_length, temperature=temperature, top_k=top_k, top_p=top_p)\n",
    "    output_area.value = generated\n",
    "\n",
    "# Create widgets\n",
    "text_input = widgets.Text(\n",
    "    value='Once upon a time',\n",
    "    description='Prompt:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "max_length_input = widgets.Text(\n",
    "    value='100',\n",
    "    description='Max Length:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "temperature_input = widgets.Text(\n",
    "    value='0.7',\n",
    "    description='Temperature:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "top_k_input = widgets.Text(\n",
    "    value='50',\n",
    "    description='Top K:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "top_p_input = widgets.Text(\n",
    "    value='0.95',\n",
    "    description='Top P:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Generate\")\n",
    "output_area = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Generated text will appear here...',\n",
    "    description='Output:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='80%', height='200px')\n",
    ")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display widgets\n",
    "display(text_input, max_length_input, temperature_input, top_k_input, top_p_input, button, output_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
